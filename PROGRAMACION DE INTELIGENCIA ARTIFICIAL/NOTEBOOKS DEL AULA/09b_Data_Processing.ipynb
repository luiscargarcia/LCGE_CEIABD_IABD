{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Procesamiento de Datos\n",
    "\n",
    "![logo](img/logo.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sumario\n",
    "- Trabajo con strings\n",
    "- Combinando datasets\n",
    "- Limpieza de datos\n",
    " - map, filter, reduce\n",
    " - filling missing values\n",
    " - valores duplicados\n",
    " - categorizacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:44:50.496319Z",
     "start_time": "2024-03-12T15:44:50.492519Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar y descomprimir   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:45:04.138075Z",
     "start_time": "2024-03-12T15:45:01.259448Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import zipfile as zp # para descomprimir archivos zip\n",
    "import urllib.request # para descargar de URL\n",
    "import os\n",
    "\n",
    "# descargar MovieLens dataset\n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'  \n",
    "local_zip = os.path.join(\"res\", \"ml-1m.zip\")\n",
    "urllib.request.urlretrieve(url, local_zip)\n",
    "# descomprimiendo archivo zip\n",
    "with zp.ZipFile(local_zip, 'r') as zipp: \n",
    "    print('Descomprimiendo ficheros...') \n",
    "    zipp.extractall(os.path.join(\"res\")) # destino\n",
    "    print('Hecho!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combinar varios datasets \n",
    "- En base a un elemento en común (índice)\n",
    "- MovieLens 'UserId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:46:57.397616Z",
     "start_time": "2024-03-12T15:46:52.235722Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join(\"res\", \"ml-1m\" )\n",
    "\n",
    "ratings_dataset = pd.read_csv(os.path.join(root_path, \"ratings.dat\"), sep='::',\n",
    "                                index_col=0, engine='python',\n",
    "                                names=['UserID','MovieID','Rating','Timestamp'])\n",
    "\n",
    "users_dataset = pd.read_csv(os.path.join(root_path, \"users.dat\"),sep='::',\n",
    "                              index_col=0, engine='python',\n",
    "                              names=['UserID','Gender','Age','Occupation','Zip-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:47:00.846840Z",
     "start_time": "2024-03-12T15:47:00.836449Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "users_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:47:03.957370Z",
     "start_time": "2024-03-12T15:47:03.925530Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ratings_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Uniendo datasets con 'join' y 'merge'\n",
    "- merge() == join()\n",
    " - 'join' utiliza por defecto los índices para unir\n",
    "- Utilizando el parámetro 'on'\n",
    " - Si las columnas difieren, 'left_on' y 'right_on'\n",
    " \n",
    " https://i.stack.imgur.com/hMKKt.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para combinar datasets podemos usar ```merge()```, estableciendo que columna se usará como 'enlace' con el parámetro **on** y especificando el tipo de 'join' con el parámetro **how**.   \n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:48:02.747309Z",
     "start_time": "2024-03-12T15:48:02.600228Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Combinando users y ratings, ¿Cómo?\n",
    "# Con merge(), especificamos el dataset con el que queremos combinar, y la columna que se usará como pivote, en este caso 'UserID'\n",
    "# También especificamos el tipo de combinación, en este caso 'inner', que solo incluirá los registros que tengan un valor en ambas tablas\n",
    "combined_dataset = users_dataset.merge(ratings_dataset, on='UserID', how='inner') \n",
    "display(combined_dataset.sample(5))\n",
    "len(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:50:31.893459Z",
     "start_time": "2024-03-12T15:50:31.860562Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualizando el dataset de películas (movies)\n",
    "movies_dataset = pd.read_csv(os.path.join(root_path, \"movies.dat\"),sep='::',encoding='latin-1', engine='python',names=['MovieID','Title','Genre'])\n",
    "movies_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:50:38.885402Z",
     "start_time": "2024-03-12T15:50:38.572090Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Combinando movies y el resto\n",
    "# Tomamos el combined_dataset y lo unimos con movies_dataset, usando 'MovieID' como pivote\n",
    "# También este caso, usamos 'inner' para que solo se incluyan los registros que tengan un valor en ambas tablas\n",
    "all_dataset = combined_dataset.merge(movies_dataset,on='MovieID', how='inner')\n",
    "all_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenación con PANDAS (```concat()```)\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método ```concat()``` de Pandas, es un método que nos permite concatenar objetos de Pandas (Series o DataFrames) a lo largo de un eje en particular.   \n",
    " \n",
    "A continuación veremos un pequeño ejemplo sobre como funciona este método y cómo podemos utilizarlo para concatenar información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cliente_uno = pd.DataFrame({\n",
    "    'Identificador': [1, 2, 3, 4, 5],\n",
    "    'Nombre': ['James', 'Emma', 'Liam', 'Olivia', 'William'],\n",
    "    'Edad': [25, 30, 22, 24, 32],\n",
    "    'Email': ['james@email.com', 'emma@email.com', 'liam@email.com', 'olibia@email.com', 'william@email.com'],\n",
    "    'Telefono': ['1234567890', '0987654321', '1230984567', '1234567893', '1237897654'],\n",
    "})\n",
    "\n",
    "clientes_dos = pd.DataFrame({\n",
    "    'Identificador': [6, 7, 8, 9, 10],\n",
    "    'Nombre': ['Jane', 'Henry', 'Alexander', 'Mia', 'Ava'],\n",
    "    'Edad': [28, 35, 26, 27, 40],\n",
    "    'Email': ['janet@gmail.com', 'henry@email.com', 'alexander@email.com', 'mia@gmail.com', 'ava@email.com'],\n",
    "})\n",
    "\n",
    "clientes_totales = pd.concat([cliente_uno, clientes_dos], ignore_index=True)\n",
    "print(clientes_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método permite concatenar dos objetos de Pandas a lo largo de cualquier eje, verticalmente u horizontalmente. En el anterior ejemplo se concatenan los dos Dataframes verticalmente y además se puede ver que al segundo Dataframe, en la columna Telefono, le coloca el valor de NaN. Esto sucede porque el primer DataFrame tiene valores en esta columna pero el segundo no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Concatenando por FILAS (Verticalmente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, concatenamos los dos Dataframes de usuarios utilizando el método ```concat()``` y le pasamos los dos Dataframes en una lista.    \n",
    "\n",
    "Esto creará un nuevo Dataframe con la información de todos los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "users_us = pd.DataFrame({\n",
    "    'User_id': [1, 2, 3, 4, 5],\n",
    "    'Username': ['Alice', 'Bob', 'Charlie', 'Jane', 'Thomas'],\n",
    "    'Age': [25, 30, 22, 24, 34]\n",
    "})\n",
    "\n",
    "users_mx = pd.DataFrame({\n",
    "    'User_id': [6, 7, 8],\n",
    "    'Username': ['Axel', 'Camilo', 'Ariana'],\n",
    "    'Age': [28, 35, 26]\n",
    "})\n",
    "\n",
    "all_users = pd.concat([users_us, users_mx], ignore_index=True) # el parametro ignore_index=True, es para que los indices se reasignen de forma secuencial.  \n",
    "print(all_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Concatenando por COLUMNAS (Horizontalmente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo tenemos tres diferentes Dataframes:   \n",
    "\n",
    "- el primero contiene varios países de América, \n",
    "- el segundo países de Europa y \n",
    "- el tercero países de Asia.    \n",
    "\n",
    "Para concatenar estos tres Dataframes horizontalmente, simplemente necesitamos usar el método ```concat()``` con dos parámetros:   \n",
    "\n",
    "- el primero son los tres Dataframes dentro de una lista y \n",
    "- el segundo parámetro es ```axis=1``` que le indica al método que tiene que hacer la concatenación horizontalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countries_america = pd.DataFrame({\n",
    "    'Country_code': ['USA', 'CAN', 'MX', \"COL\"],\n",
    "    'Population': [330, 29, 38, 67]\n",
    "})\n",
    "\n",
    "countries_europe = pd.DataFrame({\n",
    "    'Country_code': ['GER', 'FRA', 'ITA'],\n",
    "    'Population': [83, 67, 60]\n",
    "})\n",
    "\n",
    "countries_asia = pd.DataFrame({\n",
    "    'Country_code': ['CN', 'IN', 'JP'],\n",
    "    'Population': [57, 77, 63]\n",
    "})\n",
    "# concatenamos horizontalmente los dataframes\n",
    "all_countries = pd.concat([countries_america, countries_europe, countries_asia], axis=1)\n",
    "print(all_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Concatenar Dataframes con claves de nivel superior (MultiIndex)   \n",
    "\n",
    "En el ejemplo siguiente tenemos un conjunto de Dataframes similar al ejemplo anterior, pero en este caso queremos concatenarlos verticalmente y colocarle una clave a cada uno de ellos.    \n",
    "\n",
    "Para esto, simplemente debemos pasarle al método ```concat()``` la lista de Dataframes y además el parámetro ```keys``` con una lista que contine las claves para cada uno de los Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countries_america = pd.DataFrame({\n",
    "    'Country_code': ['USA', 'CAN', 'MX', \"COL\"],\n",
    "    'Population': [330, 29, 38, 67]\n",
    "})\n",
    "\n",
    "countries_europe = pd.DataFrame({\n",
    "    'Country_code': ['GER', 'FRA', 'ITA'],\n",
    "    'Population': [83, 67, 60]\n",
    "})\n",
    "\n",
    "countries_asia = pd.DataFrame({\n",
    "    'Country_code': ['CN', 'IN', 'JP'],\n",
    "    'Population': [57, 77, 63]\n",
    "})\n",
    "\n",
    "all_countries = pd.concat([countries_america, countries_europe, countries_asia], keys=['America', 'Europa', 'Asia'])\n",
    "print(all_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Concatenar Series a lo largo de las filas.   \n",
    "\n",
    "El método ```concat()``` también nos permite concatenar Series.    \n",
    "\n",
    "En el siguiente ejemplo disponemos de dos Series con el id de varios usuarios. Para concatenarlos simplemente necesitamos utilizar el método ```concat()``` y pasarle la lista de Series que queremos concatenar. También se puede hacer uso de los demás parámetros para modificar la concatenación según sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_ids_uno = pd.Series([1, 2, 3, 4, 5], name='User_id')\n",
    "user_ids_two = pd.Series([6, 7, 8, 9, 10], name='User_id')\n",
    "\n",
    "all_users = pd.concat([user_ids_uno, user_ids_two], ignore_index=True)\n",
    "\n",
    "print(all_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Método ```pivot()``` de PANDAS   \n",
    "\n",
    "El método ```pivot()``` de la librería de Pandas nos permite reorganizar y transformar los datos de un DataFrame creando una nueva tabla con un formato diferente.     \n",
    "\n",
    "El método ```pivot()``` es un método de la librería de Pandas que nos permite transformar los datos de un DataFrame al reorganizar sus datos en función de las columnas existentes.    \n",
    "Permite reconfigurar los datos de manera que los valores en una columna se conviertan en nuevas columnas y se crucen con los valores de otra columna.    \n",
    "Esto es especialmente útil para crear tablas dinámicas y resúmenes de datos.\n",
    "\n",
    "El método ```pivot()``` se utiliza principalmente en situaciones en las que se desea cambiar la estructura de los datos para un análisis más conveniente.    \n",
    "Permite que los datos sean más legibles y accesibles al proporcionar una vista diferente de los mismos.    \n",
    "Este método retorna un nuevo DataFrame con los datos pivotados y no modifica el DataFrame original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "products_df = pd.DataFrame({\n",
    "    'Fecha': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
    "    'Producto': ['Samsung', 'Apple', 'Samsung', 'Apple'],\n",
    "    'Venta': [100, 150, 200, 120]\n",
    "})\n",
    "\n",
    "print(\"Información original:\")\n",
    "print(products_df)\n",
    "\n",
    "pivot_df = products_df.pivot(index='Fecha', columns='Producto', values='Venta')\n",
    "print(\"\\nInformación pivoteada:\")\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros del método ```pivot()```  \n",
    "\n",
    "El método ```pivot()``` recibe tres parámetros, siguiendo la estructura que se muestra a continuación:\n",
    "\n",
    "```data_frame.pivot(index, columns, values)```  \n",
    "\n",
    "- **index**: Este parámetro recibe como valor una columna o lista de columnas que se usan como índices en el nuevo DataFrame. Puede ser una cadena o una lista de cadenas. Si se omite, se usa el índice de DataFrame original.\n",
    "- **columns**: (required) Este parámetro recibe como valor la columna o lista de columnas que se usan como los nombre para las columnas en el nuevo DataFrame.\n",
    "- **values**: Este parámetro recibe como valor la columna o lista de columnas que se usan como los valores para el nuevo DataFrame. Si no se especifica, se utilizarán todas las columnas restantes y el resultado tendrá columnas indexadas jerárquicamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utilizar una sola columna para crear el dataframe.   \n",
    "\n",
    "En el siguiente ejemplo, se le pasa una sola columna como valor al parámetro ```index``` y al parámetro ```columns```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"producto\": [\"Apple\", \"Apple\", \"Apple\", \"Samsung\", \"Samsung\", \"Samsung\", \"Linux\", \"Linux\", \"Linux\"],\n",
    "    \"pais\": [\"Colombia\", \"Perú\", \"Ecuador\", \"Colombia\", \"Perú\", \"Ecuador\", \"Colombia\", \"Perú\", \"Ecuador\"],\n",
    "    \"año\": [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024],\n",
    "    \"ventas\": [1000, 800, 600, 1200, 900, 700, 1100, 850, 650]\n",
    "})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_pivot = df.pivot(index=\"año\", columns=\"producto\", values=\"ventas\").fillna(\"N/A\")\n",
    "\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el anterior ejemplo se hace uso del método ```pivot()``` para transformar un DataFrame de productos y se utilizan los valores de la columna año como índice, los valores de la columna producto para representar las columnas y los valor de la columna ventas para llenar los valores en el nuevo DataFrame.    \n",
    "Además se usa el método ```fillna()``` para reemplazar todos los valores NaN con el texto **N/A(No aplica)**.    \n",
    "\n",
    "En definitiva, se ha transformado el DataFrame para ver cuántas ventas ha tenido cada producto en cada año."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Utilizar una lista de columnas para crear el dataframe   \n",
    "\n",
    "El método ```drop()``` también puede recibir una lista de columnas como valores para los parámetros.    \n",
    "\n",
    "El siguiente es un ejemplo sobre cómo puede ser útil en algunas ocasiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"producto\": [\"Apple\", \"Apple\", \"Apple\", \"Samsung\", \"Samsung\", \"Samsung\", \"Linux\", \"Linux\", \"Linux\"],\n",
    "    \"pais\": [\"Colombia\", \"Perú\", \"Ecuador\", \"Colombia\", \"Perú\", \"Ecuador\", \"Colombia\", \"Perú\", \"Ecuador\"],\n",
    "    \"año\": [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024],\n",
    "    \"ventas\": [1000, 800, 600, 1200, 900, 700, 1100, 850, 650]\n",
    "})\n",
    "\n",
    "df_pivot = df.pivot(index=\"año\", columns=[\"producto\", \"pais\"], values=\"ventas\").fillna(\"N/A\")\n",
    "\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, se hace uso del método ```pivot()``` y se le pasa una lista como valor al parámetro ```columns```.    \n",
    "Esta lista contiene dos columnas (producto y pais) lo que significa que el método ```pivot()``` utilizará la columna producto y creará una columna con cada uno de sus valores.    \n",
    "Luego creará una subcolumna con los valores de la columna pais y agrega esta subcolumna a cada una de las columnas de Producto.    \n",
    "Por último hacemos uso del método ```fillna()``` para reemplazar todos los valores NaN por el texto N/A(No aplica).    \n",
    "\n",
    "\n",
    "Este ejemplo puede ser un poco confuso, pero utilizar una lista de columnas como valores para los parámetros puede ser muy útil en determinadas ocasiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método ```pivot_table()```   \n",
    "\n",
    "La principal función de ```pivot_table()``` son las agrupaciones de datos, a las que se les suelen aplicar funciones matemáticas como sumatorios, promedios, etc.    \n",
    "Si no indicamos en el parámetro ```aggfunc``` que opereción queremos hacer, por defecto, nos calculará la ***media*** de todas aquellas columnas que sean de tipo numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura del método:   \n",
    "\n",
    "```python\n",
    "pivot_table(<lista de valores>, index=<agregador primario>, columns=<agregador secundario>)\n",
    "```\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:50:55.082211Z",
     "start_time": "2024-03-12T15:50:54.835819Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# all_dataset.pivot_table('Rating', index='Gender', columns='Age')\n",
    "# all_dataset.pivot_table('Rating', index='Gender', columns='Age', aggfunc='count')\n",
    "all_dataset.pivot_table('Rating', index='Gender', columns='Age', aggfunc=['count', 'mean']) # cuenta por sexo y edad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupaciones\n",
    "- agg -> funciones estadísticas de agregación\n",
    "- Series.unique() -> valores únicos\n",
    "- pd.value_counts -> ocurrencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Manipulación de strings\n",
    "```python\n",
    "split(): separar en bloques en función de un carácter\n",
    "replace(): reemplazar un carácter por otro\n",
    "index(): encontrar la posición de un carácter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:52:00.379883Z",
     "start_time": "2024-03-12T15:52:00.372645Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Ejemplo con MovieLens: Genre\n",
    "## 1: obtener todos los géneros por separado\n",
    "## 2: crear un dataset de géneros\n",
    "## 3: por película, marcar género por separado\n",
    "## 4: unir con dataset original\n",
    "movies_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Obtener todos los géneros de forma separada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:52:42.725572Z",
     "start_time": "2024-03-12T15:52:42.714810Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Realizamos un split de la columna 'Genre' para obtener los géneros por separado, usando una función lambda\n",
    "# El carácter que usamos para separar es '|'.\n",
    "all_genres = movies_dataset['Genre'].apply(lambda x : x.split('|'))\n",
    "print(all_genres)\n",
    "\n",
    "# print([genre for x in all_genres for genre in x])\n",
    "\n",
    "# Con pd.unique() obtenemos los valores únicos de una lista y, en este caso, \n",
    "# los géneros únicos, a través del bucle que generamos dentro de unique()\n",
    "genres = pd.unique([genre for x in all_genres # bucle para cada género (genre) en la lista de géneros (all_genres)\n",
    "                    for genre in x]) # bucle para cada género (genre) dentro de la lista de géneros (x)\n",
    "display(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:53:20.316034Z",
     "start_time": "2024-03-12T15:53:20.297895Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# crear tabla con columnas por género\n",
    "zeros = np.zeros( (len(movies_dataset), len(genres)) )\n",
    "genres_frame = pd.DataFrame(zeros, columns=genres)\n",
    "genres_frame.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Crear dataset de genéros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:53:55.170495Z",
     "start_time": "2024-03-12T15:53:54.674041Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "columns_genres = genres_frame.columns # lista de generos (columnas)\n",
    "print(columns_genres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Separar los distintos géneros para cada película.   \n",
    "\n",
    "A continuación, el código se encarga de convertir una lista de géneros en formato de cadena con \"|\" en una matriz one-hot encoding, donde cada película tiene un 1 en las columnas que corresponden a sus géneros y 0 en las demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# enumerate(movies_dataset['Genre']) permite iterar sobre cada fila de la columna 'Genre', \n",
    "# proporcionando tanto el índice i (posición de la película en el dataset) como el contenido genre (cadena de texto con los géneros de esa película).\n",
    "for i, genre in enumerate(movies_dataset['Genre']): # Iteración sobre cada fila de la columna 'Genre'\n",
    "    # Obtener los índices de los géneros en la matriz OHE (one-hot-encoding) de géneros\n",
    "    inds = columns_genres.get_indexer(genre.split('|')) # get_indexer() retorna los indices de los generos en la lista de generos 'genre.split('|')', que convierte la cadena \"Action|Comedy\" en la lista ['Action', 'Comedy'].\n",
    "    # actualiza la fila i (película en cuestión), estableciendo 1 en las posiciones inds (las columnas correspondientes a los géneros de esa película).\n",
    "    # Es decir, convierte la información de la columna 'Genre' en un formato de codificación one-hot.\n",
    "    genres_frame.iloc[i,inds] = 1 # localiza las columnas del genero correspondiente, marca con 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:54:07.100467Z",
     "start_time": "2024-03-12T15:54:07.082495Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "genres_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Unir con dataset original.   \n",
    "\n",
    "En el siguiente paso, se une el nuevo dataset con el dataset original de películas mediante ```join()```para obtener el dataset completo con los géneros segregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:54:50.096284Z",
     "start_time": "2024-03-12T15:54:50.090756Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# unir con dataset original\n",
    "movies_split_genre = movies_dataset.join(genres_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:54:51.517731Z",
     "start_time": "2024-03-12T15:54:51.498563Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "display(movies_split_genre.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extracción del año de la película usando ```replace()``` e ```index()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:55:00.087013Z",
     "start_time": "2024-03-12T15:55:00.079476Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:58:47.757375Z",
     "start_time": "2024-03-12T15:58:47.745026Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# extraer el año de la columna Title\n",
    "def split_year(title):\n",
    "    index = title.index('(')  # establecemos el 'punto de partida' para sacar el año, usando el método index() para encontrar el primer paréntesis\n",
    "    return title[index:].replace('(','').replace(')','') #sustituimos los paréntesis por 'nada' con replace()\n",
    "    \n",
    "# crear nueva columna Year\n",
    "movies_dataset['Year'] = movies_dataset['Title'].apply(split_year) # aplicamos la función split_year() (acabada de crear) sobre la columna 'Title' y guardamos el resultado en la nueva columna 'Year'\n",
    "display(movies_dataset.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:58:56.521671Z",
     "start_time": "2024-03-12T15:58:56.509899Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# eliminar el año de la columna Title\n",
    "def remove_year(title):\n",
    "    index = title.index('(') # establecemos el 'punto de partida' para sacar el título, usando el método index() para encontrar el primer paréntesis\n",
    "    return title[:index-1].strip() # eliminamos el año y los espacios en blanco al principio y al final con strip()\n",
    "\n",
    "movies_dataset['Title'] = movies_dataset['Title'].apply(remove_year) # aplicamos la función remove_year() (acabada de crear) sobre la columna 'Title' para eliminar el año de los títulos\n",
    "movies_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresiones regulares\n",
    "https://docs.python.org/3/library/re.html\n",
    "\n",
    "- import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo localizar que 'Zip-code' tiene un formato erróneo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T15:59:06.925538Z",
     "start_time": "2024-03-12T15:59:06.912094Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "users_dataset.sample(5)\n",
    "\n",
    "# Formato válido:\n",
    "# ^\\d{5}$\n",
    "# Donde:\n",
    "# ^ = start of the string\n",
    "# \\d = decimal string\n",
    "# {5} = 5 repeticiones de decimales\n",
    "# $ = end of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "users_dataset[users_dataset['Zip-code'].str.match('^\\d{5}$') == True] # localizamos los códigos postales que cumplen con el formato correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "users_dataset[users_dataset['Zip-code'].str.match('^\\d{5}$') == False] # muestra los registros que no cumplen con el formato de 5 dígitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo extraer el año con expresiones regulares usando el formato adecuado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:01:29.197004Z",
     "start_time": "2024-03-12T16:01:29.168947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "movies_dataset = pd.read_csv(os.path.join(root_path, \"movies.dat\"),sep='::', engine='python',encoding='latin-1',names=['MovieID','Title','Genre'])\n",
    "display(movies_dataset.head(2))\n",
    "\n",
    "# (\\d{4}) -> expresión regular para encontrar el año en el título\n",
    "# Donde:\n",
    "# (= busca apertura parentesis\n",
    "# \\d = decimal string\n",
    "# {4} = 4 repeticiones de decimales\n",
    "# ) = cierre de parentesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "movies_dataset['Title'].str.extract('(\\d{4})') # extraemos los años de la columna 'Title' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando la librería ```re```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión regular del código siguiente se debe interpretar cómo:   \n",
    "- r\"^ = inicio de la cadena, \n",
    "- ( = agrupación, \n",
    "- (?! = negación de la siguiente expresión, \n",
    "- English = la palabra 'English', \n",
    "- . = cualquier carácter, \n",
    "- )* = cualquier cantidad de veces, \n",
    "- $ = fin de la cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import re  # importamos el módulo 're' para trabajar con expresiones regulares\n",
    "\n",
    "test_str = (\"English 101 Class A\\n\"\n",
    "\t\"English 201 Class B\\n\"\n",
    "\t\"Spanish 101 Class D\\n\"\n",
    "\t\"Italian 201 Class E\\n\"\n",
    "\t\"French 101 Class F\\n\")\n",
    "\n",
    "def searchAllButEnglish(text):\n",
    "  regex = r\"^((?!English).)*$\"                      # expresión regular para encontrar todas las clases excepto las de inglés. \n",
    "  matches = re.finditer(regex, text, re.MULTILINE)  # buscamos todas las coincidencias en el texto\n",
    "  for match in matches:                             # iteramos sobre las coincidencias\n",
    "    print(match)                                    # imprimimos la coincidencia\n",
    "  return match\n",
    "print(searchAllButEnglish(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo sencillo del uso de ```re```para expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "texto= \"Este es mi texto de prueba en el que voy a querer cambiar unas palabras por Perro. Simplemente buscado coincidencias para perro\";\n",
    "\n",
    "regex= r\"[Pp]erro\" # expresión regular para encontrar la palabra 'perro' o 'Perro'\n",
    "\n",
    "matches = re.findall(regex,texto) # buscamos todas las coincidencias en el texto\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operaciones con colecciones\n",
    "\n",
    "- ```reduce```: aplicar una operación y retornar un valor\n",
    "- ```filter```: retorna una secuencia con elementos que cumplen una condición\n",
    "- ```map```: aplicar  una operación y retornar una secuencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Reduce\n",
    "- Aplicar una operación matemática a cada uno de los elementos de una colección\n",
    "- Diferente de 'apply()' porque retorna un valor numérico\n",
    "- Ejemplo: Detección de géneros en años específicos\n",
    "\n",
    "https://docs.python.org/3/library/functools.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```reduce``` es muy útil cuando queremos realizar ciertas operaciones sobre una lista y devolver su resultado.    \n",
    "Por ejemplo, si queremos calcular la suma de todos los elementos de una lista, y devolver un único valor, podríamos hacerlo de la siguiente forma usando ```reduce```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:01:59.388658Z",
     "start_time": "2024-03-12T16:01:59.384758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from functools import reduce # necesario para reduce\n",
    "\n",
    "lista = [1, 3, 5, 7, 9]\n",
    "print(reduce(lambda x,y: x + y, lista)) # suma de todos los elementos de la lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos un nuevo ejemplo en el que, primero localizamos y creamos un dataset con las películas del año 1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:02:38.643757Z",
     "start_time": "2024-03-12T16:02:38.621690Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "movies_1975 = movies_split_genre[ movies_split_genre['Title'].str.contains('1975') ]\n",
    "movies_1975.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a averiguar si existe alguna película que pertenezca al género \"Drama\" dentro de ese dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:02:51.125914Z",
     "start_time": "2024-03-12T16:02:51.120788Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "any_drama = reduce(lambda x,y : bool(x) | bool(y),movies_1975['Drama']) # hay algún drama en 1975\n",
    "print(any_drama)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente bloque de código se comprueba si todas las películas del año 1975 son del género \"Comedy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "all_comedy = reduce(lambda x,y : bool(x) & bool(y),movies_1975['Comedy']) # son todas las películas de 1975 comedias?\n",
    "print(all_comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente línea nos permite saber ***si existe algún valor*** que cumpla la condición de ser del género seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:03:44.789849Z",
     "start_time": "2024-03-12T16:03:44.785344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(movies_1975['Drama'].any()) # Comprueba si hay algún valor que puede cumplir  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente caso, la comprobación es ***si todos los valores*** del dataset cumplen la condición de ser del género \"Comedy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(movies_1975['Comedy'].all()) # Comprueba si todos los valores son True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprobaremos el número de entradas que existe en el dataset que cumplan la condición de tener el género \"Comedy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:03:48.524791Z",
     "start_time": "2024-03-12T16:03:48.518573Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Observar el tipo de dato antes para ver si es posible aplicar las funciones\n",
    "print(movies_1975.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(movies_1975['Comedy']) # esto muestra por pantalla la columna 'Comedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(movies_1975['Comedy'].value_counts()) # esto muestra por pantalla la cantidad de entradas únicas en la columna 'Comedy' (con valor 1.0) = 6 entradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Filter   \n",
    "\n",
    "La función ```filter``` crea una lista de elementos si usados en la llamada a una función devuelven ```True``` Es decir, filtra los elementos de una lista usando un determinado criterio.\n",
    "\n",
    "- retorna una secuencia con elementos que cumplen una condición.    \n",
    "\n",
    "La función ```filter``` es similar a un bucle ( se podría conseguir lo mismo con un bucle y un ```if```) pero su uso es más rápido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lista = range(-5, 5)\n",
    "menor_cero = list(filter(lambda x: x < 0, lista))\n",
    "print(menor_cero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro dataset de películas: obtener las películas de 1975 que contienen 'The' en el título"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:04:07.377840Z",
     "start_time": "2024-03-12T16:04:07.373087Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "filtro = filter(lambda x : 'The' in x, movies_1975['Title']) # filtramos las películas de 1975 que contienen 'The' en el título.\n",
    "list(filtro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Map   \n",
    "\n",
    "El uso de ```map``` aplica una determinada función/operación a todos los elementos de una entrada o lista, retornando una secuencia. Esta es su forma:   \n",
    "\n",
    "```map(funcion_a_aplicar, lista_de_entradas)```\n",
    "\n",
    "Un sencillo ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "lista = [1, 2, 3, 4, 5]\n",
    "al_cuadrado = list(map(lambda x: x**2, lista))\n",
    "print(al_cuadrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, sobre el dataset películas, se desea cambiar el valor integral de la columna 'Comedy' por bool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:04:24.786395Z",
     "start_time": "2024-03-12T16:04:24.764920Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "mapa = map(lambda x : bool(x), movies_1975['Comedy'])   # mapeamos la columna 'Comedy' de movies_1975 a booleanos, generando una lista de valores booleanos.\n",
    "mapa1 =map(lambda x : bool(x), movies_1975['Comedy'])   # duplicamos la línea anterior para mostrar el resultado, ya que al aplicar map() no se ejecuta la función hasta que se solicita.\n",
    "\n",
    "print(list(mapa1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "movies_1975.loc[:,'Comedy'] = list(mapa)                # actualizamos la columna 'Comedy' con los valores booleanos\n",
    "movies_1975.head(4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de usar ```map``` es combinando una lista de funciones en lugar de una sola. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def multiplicar(x):\n",
    "    return (x*x)\n",
    "def sumar(x):\n",
    "    return (x+x)\n",
    "\n",
    "funcs = [multiplicar, sumar]\n",
    "for i in range(5):\n",
    "    valor = list(map(lambda x: x(i), funcs)) # nos devuelve la multiplicación y la suma de cada valor de i (0, 1, 2, 3, 4)\n",
    "    print(valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformación de variables (calidad de datos)\n",
    "- Tratamiento de valores no definidos\n",
    "- Tratamiento de valores duplicados\n",
    "- Discretización (valores categóricos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de valores no definidos (NaN, null,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:04:53.297930Z",
     "start_time": "2024-03-12T16:04:53.285648Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Preparación del dataframe de ejemplo\n",
    "matrix = pd.DataFrame(np.random.randint(10,size=(5,10)))    # creamos un DataFrame de 5x10 con valores aleatorios entre 0 y 9\n",
    "matrix[matrix < 2] = np.nan                                 # reemplazamos los valores menores a 2 por NaN\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar cantidad de valores nulos por columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:04:58.945477Z",
     "start_time": "2024-03-12T16:04:58.939760Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# nulos por columna\n",
    "matrix.isnull().sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Si usamos la función isna() en lugar de isnull(), obtendremos el mismo resultado\n",
    "matrix.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad total de valores nulos en el dataframe matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:01.744781Z",
     "start_time": "2024-03-12T16:05:01.739241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Cantidad valores nulos\n",
    "matrix.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recuento de valores no nulos por fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:03.260518Z",
     "start_time": "2024-03-12T16:05:03.252891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# numero de no nulos por fila\n",
    "matrix.count(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recuento de valores nulos por fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:04.222829Z",
     "start_time": "2024-03-12T16:05:04.216853Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Número de nulos por fila\n",
    "matrix.shape[1] - matrix.count(axis=1) # tomamos el número de columnas y restamos el número de valores no nulos por fila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar filas que tienen alguna columna (la indicada) con valores determinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:04.952899Z",
     "start_time": "2024-03-12T16:05:04.937759Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Representación de las filas en las que una determinada columna tiene nulos\n",
    "matrix[matrix[6].isnull()] # muestra las filas en las que la columna 6 tiene valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar filas en las que una determinada columna contiene un conjunto concreto de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:06.331866Z",
     "start_time": "2024-03-12T16:05:06.314429Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "valores = [8, 4] # valores a buscar\n",
    "matrix[matrix[6].isin(valores)] # muestra las filas en las que la columna 6 tiene valores 8 o 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:07.510295Z",
     "start_time": "2024-03-12T16:05:07.501724Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## Tratamiento de valores nulos\n",
    "# eliminar\n",
    "matrix.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el parámetro ```thresh```(Umbral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:08.684031Z",
     "start_time": "2024-03-12T16:05:08.671079Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# eliminar si no hay un número de valores no NaN\n",
    "matrix.dropna(thresh=7) # elimina las filas que tienen menos de 7 valores no NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustituir/Rellenar nulos por un determinado valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:09.973046Z",
     "start_time": "2024-03-12T16:05:09.959801Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# sustituir por un valor fijo\n",
    "matrix.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustitución/Relleno dinámico.   \n",
    "\n",
    "sustituir por valor dinámico...\n",
    "- bfill -> backward fill (relleno hacia atrás)\n",
    "- ffill -> forward fill (relleno hacia adelante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:10.951882Z",
     "start_time": "2024-03-12T16:05:10.900206Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "print(matrix)\n",
    "matrix.fillna(method='bfill') # bfill y ffill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sustitución por interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:12.636227Z",
     "start_time": "2024-03-12T16:05:12.620439Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# sustituir por valor dinámico (interpolación)\n",
    "print(matrix)\n",
    "matrix.interpolate() # interpolación lineal. Establece los valores NaN en función de los valores adyacentes, asignando un valor intermedio, en este caso, la media entre los valores adyacentes.\n",
    "print(matrix.interpolate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tratar valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:15.550835Z",
     "start_time": "2024-03-12T16:05:15.539278Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "serie = pd.Series(['a','b','c','a','c','a','g'])\n",
    "serie.duplicated() # muestra los valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:16.857824Z",
     "start_time": "2024-03-12T16:05:16.833659Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df = all_dataset\n",
    "df\n",
    "# eliminar\n",
    "# Eliminación de los duplicados en una columna definida\n",
    "df2 = df.drop_duplicates(subset=\"Gender\", keep='last', inplace=False)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discretización (valores categóricos)\n",
    "- Tras Series y DataFrame, objeto para categorías: Categorical\n",
    "```python\n",
    "categorias = pd.cut(<valores>, <bins>) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:19.200566Z",
     "start_time": "2024-03-12T16:05:19.165154Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# especificar los bloques\n",
    "bins = [0,18,35,65,99]\n",
    "edades = [16,25,18,71,44,100,12]\n",
    "categorias = pd.cut(edades,bins) # cut divide los valores en los bloques especificados\n",
    "print(categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:20.214098Z",
     "start_time": "2024-03-12T16:05:20.205134Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "categorias.value_counts() # muestra la cantidad de valores en cada bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:21.490494Z",
     "start_time": "2024-03-12T16:05:21.481222Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# especificar el número de bloques\n",
    "bins = 5                         # número de bloques. En este caso, 5 bloques que no se especifican, sino que se generan automáticamente, de forma que tengan una distancia similar entre ellos.\n",
    "edades = [0,6,8,16,25,18,71,44,100]\n",
    "categorias = pd.cut(edades,bins) # rangos idénticos (similar distancia de rangos)\n",
    "print(categorias)                # muestra los bloques en los que se dividen los valores\n",
    "print(categorias.value_counts()) # muestra la cantidad de valores en cada bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T16:05:22.941835Z",
     "start_time": "2024-03-12T16:05:22.934575Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "bins = 5\n",
    "edades = [1,6,8,16,25,18,71,44,100]\n",
    "categorias = pd.qcut(edades,bins) # rangos homogéneos (similar número de valores). qcut divide los valores en bloques de igual tamaño.\n",
    "print(categorias)\n",
    "print(categorias.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <img src=\"img/by-nc.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

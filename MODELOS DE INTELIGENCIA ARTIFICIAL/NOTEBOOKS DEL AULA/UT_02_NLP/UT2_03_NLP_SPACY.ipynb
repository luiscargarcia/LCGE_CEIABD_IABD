{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP con librería SPACY\n",
    "\n",
    "Al igual que NLTK, spaCy es una librería de procesamiento de lenguaje natural (PLN) para Python de código abierto.    \n",
    "**spaCy** ofrece a los usuarios un conjunto de herramientas y modelos para realizar diversas tareas relacionadas con el procesamiento y análisis de texto.    \n",
    "Las principales características de **spaCy** son:   \n",
    "\n",
    "1. **Tokenización**: puede dividir texto en unidades más pequeñas llamadas “tokens”, que pueden ser palabras o partes de palabras.\n",
    "2. **Etiquetado gramatical**: contiene modelos entrenados que pueden etiquetar cada token en un texto con información gramatical, como partes del discurso y etiquetas sintácticas.\n",
    "3. **Reconocimiento de entidades nombradas**: permite identificar y clasificar entidades nombradas en un texto, como nombres de personas, organizaciones, lugares, fechas, cantidades, entre otros.\n",
    "4. **Análisis sintáctico**: facilita la realización de análisis sintáctico de las oraciones para capturar la estructura gramatical y las dependencias entre las palabras.\n",
    "5. **Lematización**: reduce las palabras a su forma base (lemas), lo que ayuda a normalizar el texto y simplificar el análisis.\n",
    "6. **Modelos pre-entrenados**: proporciona modelos pre-entrenados para varios idiomas que pueden utilizarse para realizar tareas de PLN sin la necesidad de entrenar un modelo desde cero. Estos modelos incluyen información gramatical, reconocimiento de entidades y análisis sintáctico.\n",
    "7. **Eficiencia y velocidad**: es una librería rápida y eficiente, lo que la hace adecuada para el procesamiento de grandes volúmenes de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de sentimientos en español con spaCy.\n",
    "\n",
    "Los pasos para realizar análisis de sentimiento en español con spaCy son los mismos que se realizan con NLTK en inglés.    \n",
    "Obviamente, las funciones que se deben usar son diferentes. En concreto, los pasos que se deben seguir son:   \n",
    "\n",
    "- preprocesamiento de datos, \n",
    "- extracción de características, \n",
    "- entrenamiento del modelo y \n",
    "- clasificación de nuevos textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocesamiento de datos   \n",
    "\n",
    "El procesamiento de datos en spaCy es ligeramente más sencillo en spaCy que en NLTK.    \n",
    "En este caso concreto, se deben importar los modelos entrenados que se han descargado antes y usarlos para obtener los tokens ya tematizados y en minúsculas.    \n",
    "Este proceso se realiza en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encantar contenido blog inteligencia artificial artículo fantástico'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A instalar desde la terminal:\n",
    "# pip install spacy\n",
    "# python -m spacy download es_core_news_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "text = \"Me encanta el contenido del blog de Inteligencia Artificial, los artículos son fantásticos.\"\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "# Eliminación de palabras irrelevantes (stopwords) y signos de puntuación\n",
    "tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "# Reconstrucción del texto preprocesado\n",
    "preprocessed_text = ' '.join(tokens)\n",
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque de código se cargan los modelos mediante la función ```spacy.load()``` (si se ha descargado otro se deberá reemplazar el nombre en el parámetro de la función por el que se desee usar).    \n",
    "Al modelo importado se le puede pasar la cadena de texto para obtener los tokens (```nlp(text)```).    \n",
    "Posteriormente se filtran aquellos que no son ni stopwords ni elementos de puntuación (```not token.is_stop and not token.is_punct```) para, en el mismo paso, ***lematizar*** y convertir en minúsculas (```token.lemma_.lower()```). El resultado es el listado de tokens procesados.\n",
    "\n",
    "Se puede observar como la herramienta usa como token el **infinitivo del verbo** en lugar de su versión conjugada (encantar en lugar de encanta). También **los términos en plural aparecen en singular** (artículo en lugar de artículos). Todo esto facilita el análisis de los textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracción de características\n",
    "\n",
    "En spaCy, la extracción de características también se puede hacer de una forma sencilla. Para ello, se debe iterar sobre los tokens y crear una lista con el conteo de términos.   \n",
    "\n",
    "Una posible opción para hacer esto es la que se muestra en el siguiente código de ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encantar': 1,\n",
       " 'contenido': 1,\n",
       " 'blog': 1,\n",
       " 'inteligencia': 1,\n",
       " 'artificial': 1,\n",
       " 'artículo': 1,\n",
       " 'fantástico': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {}\n",
    "doc = nlp(preprocessed_text)\n",
    "\n",
    "for token in doc:\n",
    "    if not token.is_stop and not token.is_punct:\n",
    "        if token.lemma_.lower() in features:\n",
    "            features[token.lemma_.lower()] += 1\n",
    "        else:\n",
    "            features[token.lemma_.lower()] = 1\n",
    "            \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto genera un diccionario donde la palabra es la clave y el valor es el número de ocurrencias de esta en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conjunto de datos de entrenamiento y factorización de los datos.   \n",
    "\n",
    "Antes de llevar a cabo un análisis de sentimientos en español con spaCy, es necesario disponer de un conjunto de datos para el entrenamiento. Para ello se recurre a una traducción de un conjunto de datos definido por nosotros y que realizamos en el bloque de código siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"Me encanta el contenido del blog de Inteligencia Artificial, los artículos son fantásticos.\", \"positivo\"),\n",
    "    (\"El código no funciona, me ha dado un error al ejecutarlo.\", \"negativo\"),\n",
    "    (\"Me encanta este producto.\", \"positivo\"),\n",
    "    (\"Esta película fue terrible.\", \"negativo\"),\n",
    "    (\"El clima está agradable hoy.\", \"positivo\"),\n",
    "    (\"Me siento triste por las noticias.\", \"negativo\"),\n",
    "    (\"Es solo un libro promedio.\", \"neutral\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede optar por crear funciones con las que se factorizan los pasos vistos en los apartados anteriores, de forma que el código final sea más modular.   \n",
    "\n",
    "Por ejemplo:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Realiza el preprocesamiento básico de un texto en idioma español utilizando spaCy.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto a ser preprocesado.\n",
    "\n",
    "    Returns:\n",
    "        str: El texto preprocesado.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('es_core_news_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Eliminación de palabras irrelevantes (stopwords) y signos de puntuación\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    # Reconstrucción del texto preprocesado\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extrae las características del texto utilizando spaCy y devuelve un diccionario de características.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto del cual extraer características.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario que representa las características extraídas del texto.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            if token.lemma_.lower() in features:\n",
    "                features[token.lemma_.lower()] += 1\n",
    "            else:\n",
    "                features[token.lemma_.lower()] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento del modelo\n",
    "Para el análisis de sentimientos, uno de los modelos/algoritmos que mejor funciona es **Naive Bayes**. A diferencia de NLTK, spaCy no cuenta con una implementación propia, pero se puede optar por la de que se dispone en Scikit-learn.    \n",
    "Por tanto, para entrenar el modelo solamente sería necesario preprocesar los datos, extraer las características y crear un conjunto de entrenamiento para el **modelo MultinomialNB() (Multinomial Naive Bayes)**.    \n",
    "\n",
    "Los pasos que a implementar son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Preprocesamiento de los datos de entrenamiento\n",
    "preprocessed_training_data = [(preprocess_text(text), label) for text, label in training_data]\n",
    "\n",
    "# Extracción de características de los datos de entrenamiento\n",
    "training_features = [extract_features(text) for text, _ in preprocessed_training_data]\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_train = vectorizer.fit_transform(training_features)\n",
    "\n",
    "# Etiquetas de los datos de entrenamiento\n",
    "y_train = [label for _, label in preprocessed_training_data]\n",
    "\n",
    "# Entrenamiento del clasificador Naive Bayes\n",
    "classifier = MultinomialNB()\n",
    "_ = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Clasificación de nuevos textos\n",
    "\n",
    "Una vez entrenado el modelo, este se puede usar para predecir el sentimiento de nuevos textos.    \n",
    "Simplemente se repiten con los nuevos textos las transformaciones realizadas sobre el conjunto de entrenamiento y el resultado se le pasa al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimiento: positivo\n"
     ]
    }
   ],
   "source": [
    "# Nuevo texto para clasificar\n",
    "new_text = \"Me encantó mucho del concierto.\"\n",
    "\n",
    "# Preprocesamiento del nuevo texto\n",
    "preprocessed_text = preprocess_text(new_text)\n",
    "\n",
    "# Extracción de características del nuevo texto\n",
    "features = extract_features(preprocessed_text)\n",
    "X_test = vectorizer.transform([features])\n",
    "\n",
    "# Clasificación del nuevo texto\n",
    "sentiment = classifier.predict(X_test)\n",
    "print(\"Sentimiento:\", sentiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones.   \n",
    "\n",
    "\n",
    "**spaCy** es una librería alternativa a **NLTK** con la que también se puede realizar análisis de sentimientos. Contando con la ventaja de que también se puede hacer en español y otros idiomas gracias a los modelos pre-entrenados que se pueden descargar.    \n",
    "Esto también simplifica el trabajo con la librería. Por eso, en el caso de querer realizar análisis de sentimientos en español, spaCy es una de las opciones que siempre se debe tener en cuenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Anexo*. Detección de entidades nombradas (Named Entity Recognition NER)   \n",
    "\n",
    "Esta funcionalidad nos permite tokenizar el texto e identificar palabras clave, extrayendo información que indica y clasifica en categorías como organizaciones, lugares, cantidades,...\n",
    "\n",
    "El código siguiente muestra un pequeño ejemplo de ello, haciendo uso de un complemento de la propia librería `spaCy` denominado [`displaCy`](https://demos.explosion.ai/displacy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Castilla y León', 'LOC'), ('provincia de Valladolid', 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import es_core_news_sm\n",
    "nlp = es_core_news_sm.load()\n",
    "doc = nlp(\"Me encanta el viajar por Castilla y León, sobretodo por la provincia de Valladolid.\")\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"es\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Me encanta el viajar por \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Castilla y León\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", sobretodo por la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    provincia de Valladolid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5001 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.17.0.1 - - [16/Mar/2025 18:09:24] \"GET / HTTP/1.1\" 200 1112\n",
      "172.17.0.1 - - [16/Mar/2025 18:09:24] \"GET /favicon.ico HTTP/1.1\" 200 1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5001.\n"
     ]
    }
   ],
   "source": [
    "# spacy.displacy.serve(doc, style=\"ent\") # Para visualizar en un navegador web local\n",
    "# Se ha modificado el fichero devcontainer.json para que el puerto 5001 esté disponible!!!\n",
    "spacy.displacy.serve(doc, style=\"ent\", port=5001, host='0.0.0.0') # Para visualizar en un navegador web externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Me encanta el viajar por \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Castilla y León\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", sobretodo por la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    provincia de Valladolid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Renderizado directo sobre Jupyter Notebook\n",
    "displacy.render(nlp(str(doc)), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"0a4f1ac52fcc4e45915e032a81338902-0\" class=\"displacy\" width=\"1170\" height=\"257.0\" direction=\"ltr\" style=\"max-width: none; height: 257.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Me</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">encanta</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">el</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">viajar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">por</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">Castilla</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">y</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">León,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">sobretodo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">por</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">provincia</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"167.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1090\">Valladolid.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1090\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-0\" stroke-width=\"2px\" d=\"M70,122.0 C70,82.0 120.0,82.0 120.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">iobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,124.0 L62,112.0 78,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-1\" stroke-width=\"2px\" d=\"M230,122.0 C230,82.0 280.0,82.0 280.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M230,124.0 L222,112.0 238,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-2\" stroke-width=\"2px\" d=\"M150,122.0 C150,42.0 285.0,42.0 285.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">csubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M285.0,124.0 L293.0,112.0 277.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-3\" stroke-width=\"2px\" d=\"M390,122.0 C390,82.0 440.0,82.0 440.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390,124.0 L382,112.0 398,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-4\" stroke-width=\"2px\" d=\"M310,122.0 C310,42.0 445.0,42.0 445.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M445.0,124.0 L453.0,112.0 437.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-5\" stroke-width=\"2px\" d=\"M550,122.0 C550,82.0 600.0,82.0 600.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,124.0 L542,112.0 558,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-6\" stroke-width=\"2px\" d=\"M470,122.0 C470,42.0 605.0,42.0 605.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M605.0,124.0 L613.0,112.0 597.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-7\" stroke-width=\"2px\" d=\"M470,122.0 C470,2.0 690.0,2.0 690.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M690.0,124.0 L698.0,112.0 682.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-8\" stroke-width=\"2px\" d=\"M790,122.0 C790,42.0 925.0,42.0 925.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,124.0 L782,112.0 798,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-9\" stroke-width=\"2px\" d=\"M870,122.0 C870,82.0 920.0,82.0 920.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,124.0 L862,112.0 878,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-10\" stroke-width=\"2px\" d=\"M710,122.0 C710,2.0 930.0,2.0 930.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,124.0 L938.0,112.0 922.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-11\" stroke-width=\"2px\" d=\"M1030,122.0 C1030,82.0 1080.0,82.0 1080.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030,124.0 L1022,112.0 1038,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0a4f1ac52fcc4e45915e032a81338902-0-12\" stroke-width=\"2px\" d=\"M950,122.0 C950,42.0 1085.0,42.0 1085.0,122.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0a4f1ac52fcc4e45915e032a81338902-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,124.0 L1093.0,112.0 1077.0,112.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(doc)), style='dep', jupyter = True, options = {'distance': 80})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, lematizamos esta frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('encanta', 'VERB', 'encantar'),\n",
       " ('viajar', 'VERB', 'viajar'),\n",
       " ('Castilla', 'PROPN', 'Castilla'),\n",
       " ('León', 'PROPN', 'León'),\n",
       " ('sobretodo', 'NOUN', 'sobretodo'),\n",
       " ('provincia', 'NOUN', 'provincia'),\n",
       " ('Valladolid', 'PROPN', 'Valladolid')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(str(doc)) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, usando un diccionario, extraemos las N.E.R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Castilla y León': 'LOC', 'provincia de Valladolid': 'LOC'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(str(x), x.label_) for x in nlp(str(doc)).ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Anexo. Similitud de textos.   \n",
    "\n",
    "Determinados modelos han sido entrenados de manera que las palabras se etiquetan aludiendo a conceptos semánticos. Por ejemplo, un perro es un mamífero y, a su vez, un animal. Un etiquetado correcto nos situa en lugares más próximos entre sí a un perro y a un gato (dos mamíferos) que a un perro y a un salmón. De igual forma, una manzana es a la vez fruta y comida, aunque la manzana se parece más a una naranja que a un filete de ternera, tratándose en ambos casos de comida.     \n",
    "\n",
    "Usando técnicas de vectorización y cálculo, se puede analizar dos textos y establecer la similitud que tienen entre sí, aunque obviamente sea algo muy \"subjetivo\" y dependiente del dataset usado en el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente es un ejemplo ilustrativo de un cálculo de similitud mediante la librería `spaCy`, usando  el diccionario español usado en este mismo notebook en los ejemplos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download es_core_news_lg\n",
    "import es_core_news_lg\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = es_core_news_lg.load()\n",
    "doc1 = nlp(\"Carlos se come una manzana\")\n",
    "doc2 = nlp(\"Maria se come una ensalada\")\n",
    "doc3 = nlp(\"Maria y Carlos se comen una pizza\")\n",
    "doc4 = nlp(\"Maria y Carlos ven una película\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlos se come una manzana <-> Maria se come una ensalada  -->  0.9487316608428955\n",
      "Carlos se come una manzana <-> Maria y Carlos se comen una pizza  -->  0.8953322172164917\n",
      "Carlos se come una manzana <-> Maria y Carlos ven una película  -->  0.34944161772727966\n",
      "Maria se come una ensalada <-> Maria y Carlos se comen una pizza  -->  0.9006785154342651\n",
      "Maria se come una ensalada <-> Maria y Carlos ven una película  -->  0.3849201202392578\n",
      "Carlos se come una manzana <-> Maria y Carlos ven una película  -->  0.34944161772727966\n"
     ]
    }
   ],
   "source": [
    "# Similaridad entre dos documentos\n",
    "print(doc1, \"<->\", doc2, \" --> \", doc1.similarity(doc2))\n",
    "print(doc1, \"<->\", doc3, \" --> \", doc1.similarity(doc3))\n",
    "print(doc1, \"<->\", doc4, \" --> \", doc1.similarity(doc4))\n",
    "print(doc2, \"<->\", doc3, \" --> \", doc2.similarity(doc3))\n",
    "print(doc2, \"<->\", doc4, \" --> \", doc2.similarity(doc4))\n",
    "print(doc1, \"<->\", doc4, \" --> \", doc1.similarity(doc4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos distintos niveles de similitud, en función de la \"actividad\" realizada (verbo) y como, incluso cambiando el sujeto, también nos marca distinto valor en acciones similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlace de interés para comprender visualmente esta similitud y como funcionan las técnicas de [`word embbeding`](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

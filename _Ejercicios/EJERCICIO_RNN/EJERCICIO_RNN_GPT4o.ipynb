{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y Exploración de Datos\n",
    "Carga el conjunto de datos 'Individual household electric power consumption dataset' y realiza una exploración inicial de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip'\n",
    "data = pd.read_csv(url, sep=';', parse_dates={'datetime': ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['nan','?'])\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos\n",
    "data.head()\n",
    "\n",
    "# Información general del conjunto de datos\n",
    "data.info()\n",
    "\n",
    "# Estadísticas descriptivas del conjunto de datos\n",
    "data.describe()\n",
    "\n",
    "# Visualización de los datos faltantes\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Datos faltantes en el conjunto de datos')\n",
    "plt.xlabel('Columnas')\n",
    "plt.ylabel('Número de datos faltantes')\n",
    "data.isnull().sum().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de las series temporales de consumo de energía\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(data['datetime'], data['Global_active_power'], label='Consumo de energía activa global')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Consumo de energía (kilovatios)')\n",
    "plt.title('Consumo de energía activa global a lo largo del tiempo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos\n",
    "Limpia los valores faltantes, normaliza los datos y prepara los datos para su uso en modelos de series temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de Datos\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convertir la columna 'Global_active_power' a tipo float\n",
    "data['Global_active_power'] = data['Global_active_power'].astype(float)\n",
    "\n",
    "# Normalizar los datos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['Global_active_power'] = scaler.fit_transform(data['Global_active_power'].values.reshape(-1, 1))\n",
    "\n",
    "# Preparar los datos para su uso en modelos de series temporales\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Definir la longitud de la secuencia\n",
    "seq_length = 60\n",
    "\n",
    "# Crear secuencias\n",
    "X, y = create_sequences(data['Global_active_power'].values, seq_length)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mostrar las formas de los conjuntos de datos resultantes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación del Modelo LSTM\n",
    "Implementa un modelo de Red LSTM para predecir el consumo de energía eléctrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias para construir el modelo LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Definir el modelo LSTM\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model_lstm.add(LSTM(50, return_sequences=False))\n",
    "model_lstm.add(Dense(25))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "# Compilar el modelo\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_lstm = model_lstm.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_lstm = model_lstm.evaluate(X_test, y_test)\n",
    "print(f'Pérdida del modelo LSTM: {loss_lstm}')\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# Desnormalizar las predicciones\n",
    "predictions_lstm = scaler.inverse_transform(predictions_lstm)\n",
    "\n",
    "# Desnormalizar los valores reales\n",
    "y_test_descaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Visualizar las predicciones frente a los valores reales\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(y_test_descaled, label='Valores Reales')\n",
    "plt.plot(predictions_lstm, label='Predicciones LSTM')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Consumo de energía (kilovatios)')\n",
    "plt.title('Predicciones del modelo LSTM vs Valores Reales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación del Modelo GRU\n",
    "Implementa un modelo de Red GRU para realizar la misma tarea de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias para construir el modelo GRU\n",
    "from tensorflow.keras.layers import GRU\n",
    "\n",
    "# Definir el modelo GRU\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model_gru.add(GRU(50, return_sequences=False))\n",
    "model_gru.add(Dense(25))\n",
    "model_gru.add(Dense(1))\n",
    "\n",
    "# Compilar el modelo\n",
    "model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_gru = model_gru.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f'Pérdida del modelo GRU: {loss_gru}')\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions_gru = model_gru.predict(X_test)\n",
    "\n",
    "# Desnormalizar las predicciones\n",
    "predictions_gru = scaler.inverse_transform(predictions_gru)\n",
    "\n",
    "# Visualizar las predicciones frente a los valores reales\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(y_test_descaled, label='Valores Reales')\n",
    "plt.plot(predictions_gru, label='Predicciones GRU')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Consumo de energía (kilovatios)')\n",
    "plt.title('Predicciones del modelo GRU vs Valores Reales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del Rendimiento de los Modelos\n",
    "Evalúa el rendimiento de ambos modelos utilizando métricas como el Error Cuadrático Medio (RMSE) y el Error Absoluto Medio (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del Rendimiento de los Modelos\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Calcular RMSE y MAE para el modelo LSTM\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_descaled, predictions_lstm))\n",
    "mae_lstm = mean_absolute_error(y_test_descaled, predictions_lstm)\n",
    "\n",
    "# Calcular RMSE y MAE para el modelo GRU\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_descaled, predictions_gru))\n",
    "mae_gru = mean_absolute_error(y_test_descaled, predictions_gru)\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(f'RMSE del modelo LSTM: {rmse_lstm}')\n",
    "print(f'MAE del modelo LSTM: {mae_lstm}')\n",
    "print(f'RMSE del modelo GRU: {rmse_gru}')\n",
    "print(f'MAE del modelo GRU: {mae_gru}')\n",
    "\n",
    "# Crear una tabla comparativa de las métricas de evaluación\n",
    "import pandas as pd\n",
    "\n",
    "metrics = {\n",
    "    'Modelo': ['LSTM', 'GRU'],\n",
    "    'RMSE': [rmse_lstm, rmse_gru],\n",
    "    'MAE': [mae_lstm, mae_gru]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "\n",
    "# Visualizar las métricas de evaluación en un gráfico de barras\n",
    "metrics_df.set_index('Modelo').plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Comparación de Métricas de Evaluación')\n",
    "plt.ylabel('Valor')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de Resultados\n",
    "Compara los resultados obtenidos por los modelos LSTM y GRU, analizando sus fortalezas y debilidades en este contexto específico. Incluye gráficos que visualicen las predicciones de ambos modelos y una tabla comparativa de las métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del Rendimiento de los Modelos\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Calcular RMSE y MAE para el modelo LSTM\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_descaled, predictions_lstm))\n",
    "mae_lstm = mean_absolute_error(y_test_descaled, predictions_lstm)\n",
    "\n",
    "# Calcular RMSE y MAE para el modelo GRU\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_descaled, predictions_gru))\n",
    "mae_gru = mean_absolute_error(y_test_descaled, predictions_gru)\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(f'RMSE del modelo LSTM: {rmse_lstm}')\n",
    "print(f'MAE del modelo LSTM: {mae_lstm}')\n",
    "print(f'RMSE del modelo GRU: {rmse_gru}')\n",
    "print(f'MAE del modelo GRU: {mae_gru}')\n",
    "\n",
    "# Crear una tabla comparativa de las métricas de evaluación\n",
    "import pandas as pd\n",
    "\n",
    "metrics = {\n",
    "    'Modelo': ['LSTM', 'GRU'],\n",
    "    'RMSE': [rmse_lstm, rmse_gru],\n",
    "    'MAE': [mae_lstm, mae_gru]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)\n",
    "\n",
    "# Visualizar las métricas de evaluación en un gráfico de barras\n",
    "metrics_df.set_index('Modelo').plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Comparación de Métricas de Evaluación')\n",
    "plt.ylabel('Valor')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MÓDULO: Sistemas de Aprendizaje Automático   \n",
    "\n",
    "# Predicción del consumo de energía eléctrica con Redes LSTM y GRU: Un estudio comparativo.\n",
    "\n",
    "## Justificación:\n",
    "\n",
    "La predicción del consumo de energía eléctrica es crucial para la gestión eficiente de los recursos energéticos. En este ejercicio, aplicarás técnicas de aprendizaje profundo para predecir el consumo de energía eléctrica utilizando un conjunto de datos de series temporales.\n",
    "\n",
    "## Tarea a realizar:\n",
    "\n",
    "- Carga y explora el conjunto de datos [\"Individual household electric power consumption dataset\"](https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption) (disponible en UCI Machine Learning Repository). Este conjunto de datos contiene mediciones del consumo de energía eléctrica en un hogar durante un período de cuatro años.\n",
    "- Realiza un preprocesamiento adecuado de los datos, incluyendo la limpieza de valores faltantes, la normalización y la preparación de los datos para su uso en modelos de series temporales.\n",
    "- Implementa un modelo de Red LSTM para predecir el consumo de energía eléctrica.\n",
    "- Implementa un modelo de Red GRU para realizar la misma tarea.\n",
    "- Evalúa el rendimiento de ambos modelos utilizando métricas como el Error Cuadrático Medio (RMSE) y el Error Absoluto Medio (MAE).\n",
    "- Compara los resultados obtenidos por los modelos LSTM y GRU, analizando sus fortalezas y debilidades en este contexto específico.\n",
    "\n",
    "En definitiva, se debe elaborar un informe conciso, usando un cuaderno Jupyter, que resuma los hallazgos, incluyendo gráficos que visualicen las predicciones de ambos modelos y una tabla comparativa de las métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gemini code assit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- 1. Carga y Exploración de Datos ---\n",
    "\n",
    "# Cargar el dataset (descargado previamente y ubicado en la misma carpeta)\n",
    "try:\n",
    "    data = pd.read_csv('household_power_consumption.txt', sep=';', low_memory=False, na_values=['?'])\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'household_power_consumption.txt' no se encuentra. Asegúrate de haberlo descargado y colocado en la misma carpeta que este script.\")\n",
    "    exit()\n",
    "\n",
    "# Convertir la columna 'Date' a tipo datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Combinar 'Date' y 'Time' en una sola columna 'Datetime'\n",
    "data['Datetime'] = pd.to_datetime(data['Date'].astype(str) + ' ' + data['Time'].astype(str))\n",
    "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "data.set_index('Datetime', inplace=True)\n",
    "\n",
    "# Exploración inicial\n",
    "print(\"Información del dataset:\")\n",
    "print(data.info())\n",
    "print(\"\\nPrimeras filas:\")\n",
    "print(data.head())\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(data.describe())\n",
    "\n",
    "# --- 2. Preprocesamiento de Datos ---\n",
    "\n",
    "# 2.1. Manejo de Valores Faltantes\n",
    "print(\"\\nValores faltantes por columna antes del imputado:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Imputar valores faltantes con la media de cada columna\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "print(\"\\nValores faltantes por columna después del imputado:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 2.2. Normalización\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# 2.3. Preparación para Series Temporales\n",
    "def create_dataset(dataset, look_back=60):\n",
    "    \"\"\"Crea un dataset para series temporales con 'look_back' pasos anteriores.\"\"\"\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back - 1):\n",
    "        a = dataset[i:(i + look_back), 0]  # Solo usamos 'Global_active_power'\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "look_back = 60  # Usaremos los últimos 60 minutos para predecir el siguiente\n",
    "X, y = create_dataset(data_scaled, look_back)\n",
    "\n",
    "# Redimensionar para LSTM y GRU [samples, time steps, features]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# 2.4. División en Entrenamiento y Prueba\n",
    "train_size = int(len(X) * 0.8)\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = X[0:train_size, :], X[train_size:len(X), :]\n",
    "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
    "\n",
    "# --- 3. Modelo LSTM ---\n",
    "\n",
    "# 3.1. Construcción del Modelo\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "# 3.2. Compilación y Entrenamiento\n",
    "model_lstm.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# 3.3. Predicciones\n",
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "\n",
    "# --- 4. Modelo GRU ---\n",
    "\n",
    "# 4.1. Construcción del Modelo\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(50, input_shape=(look_back, 1)))\n",
    "model_gru.add(Dense(1))\n",
    "\n",
    "# 4.2. Compilación y Entrenamiento\n",
    "model_gru.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "# 4.3. Predicciones\n",
    "y_pred_gru = model_gru.predict(X_test)\n",
    "\n",
    "# --- 5. Evaluación de Modelos ---\n",
    "\n",
    "# 5.1. Invertir la Normalización\n",
    "y_test_inv = scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), np.zeros((len(y_test), data.shape[1]-1))), axis=1))[:,0]\n",
    "y_pred_lstm_inv = scaler.inverse_transform(np.concatenate((y_pred_lstm.reshape(-1, 1), np.zeros((len(y_pred_lstm), data.shape[1]-1))), axis=1))[:,0]\n",
    "y_pred_gru_inv = scaler.inverse_transform(np.concatenate((y_pred_gru.reshape(-1, 1), np.zeros((len(y_pred_gru), data.shape[1]-1))), axis=1))[:,0]\n",
    "\n",
    "# 5.2. Calcular Métricas\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inv, y_pred_lstm_inv))\n",
    "mae_lstm = mean_absolute_error(y_test_inv, y_pred_lstm_inv)\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_inv, y_pred_gru_inv))\n",
    "mae_gru = mean_absolute_error(y_test_inv, y_pred_gru_inv)\n",
    "\n",
    "print(\"\\nMétricas de Evaluación:\")\n",
    "print(f\"LSTM - RMSE: {rmse_lstm:.4f}, MAE: {mae_lstm:.4f}\")\n",
    "print(f\"GRU - RMSE: {rmse_gru:.4f}, MAE: {mae_gru:.4f}\")\n",
    "\n",
    "# --- 6. Comparación y Visualización ---\n",
    "\n",
    "# 6.1. Tabla Comparativa\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Model': ['LSTM', 'GRU'],\n",
    "    'RMSE': [rmse_lstm, rmse_gru],\n",
    "    'MAE': [mae_lstm, mae_gru]\n",
    "})\n",
    "print(\"\\nTabla Comparativa:\")\n",
    "print(comparison_table)\n",
    "\n",
    "# 6.2. Gráficos de Predicciones\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_inv, label='Real')\n",
    "plt.plot(y_pred_lstm_inv, label='LSTM')\n",
    "plt.plot(y_pred_gru_inv, label='GRU')\n",
    "plt.title('Predicciones vs. Valores Reales')\n",
    "plt.xlabel('Tiempo (minutos)')\n",
    "plt.ylabel('Global_active_power')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.3. Gráficos de Pérdida\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_lstm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_lstm.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM - Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_gru.history['loss'], label='Train Loss')\n",
    "plt.plot(history_gru.history['val_loss'], label='Validation Loss')\n",
    "plt.title('GRU - Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 7. Informe Conciso (Resumen) ---\n",
    "print(\"\\n--- Informe Conciso ---\")\n",
    "print(\"Resumen de Hallazgos:\")\n",
    "print(\"1. Se ha realizado la carga, exploración y preprocesamiento del dataset 'Individual household electric power consumption'.\")\n",
    "print(\"2. Se han imputado los valores faltantes con la media de cada columna.\")\n",
    "print(\"3. Se ha normalizado el dataset utilizando MinMaxScaler.\")\n",
    "print(\"4. Se han preparado los datos para series temporales, utilizando un 'look_back' de 60 minutos.\")\n",
    "print(\"5. Se han implementado y entrenado dos modelos: LSTM y GRU.\")\n",
    "print(\"6. Se han evaluado ambos modelos utilizando RMSE y MAE.\")\n",
    "print(\"7. Se han generado gráficos comparativos de las predicciones y las curvas de pérdida.\")\n",
    "print(\"\\nComparación de Modelos:\")\n",
    "print(f\"- **LSTM:** RMSE: {rmse_lstm:.4f}, MAE: {mae_lstm:.4f}\")\n",
    "print(f\"- **GRU:** RMSE: {rmse_gru:.4f}, MAE: {mae_gru:.4f}\")\n",
    "print(\"\\nAnálisis:\")\n",
    "if rmse_lstm < rmse_gru and mae_lstm < mae_gru:\n",
    "    print(\"En este caso, el modelo LSTM ha mostrado un mejor rendimiento que el modelo GRU, con valores más bajos de RMSE y MAE.\")\n",
    "elif rmse_gru < rmse_lstm and mae_gru < mae_lstm:\n",
    "    print(\"En este caso, el modelo GRU ha mostrado un mejor rendimiento que el modelo LSTM, con valores más bajos de RMSE y MAE.\")\n",
    "else:\n",
    "    print(\"Los modelos LSTM y GRU han mostrado un rendimiento similar en este caso.\")\n",
    "print(\"\\nConclusión:\")\n",
    "print(\"Ambos modelos, LSTM y GRU, son capaces de predecir el consumo de energía eléctrica con una precisión razonable. La elección entre uno u otro dependerá de los requisitos específicos del problema y de la importancia relativa de la velocidad de entrenamiento y la precisión.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio RN Convolucionales, Data Augmentation y Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En este ejercicio se entrenará un nuevo modelo capaz de reconocer fruta fresca y podrida. Tendrás que conseguir que el modelo alcance una precisión de validación del `92%` para superar la evaluación, aunque te retamos a que lo hagas incluso mejor si puedes.    \n",
    " \n",
    " Te sugerimos que utilices alguna combinación de aprendizaje por transferencia, aumento de datos y ajuste fino.    \n",
    " \n",
    " Una vez que hayas entrenado el modelo para que tenga al menos un 92% de precisión en el conjunto de datos de validación, guarda tu modelo y evalúa su precisión.    \n",
    " \n",
    " ¡Adelante!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio, entrenarás un modelo para reconocer frutas frescas y podridas. El conjunto de datos proviene de [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification).\n",
    "\n",
    "La estructura del conjunto de datos está en la carpeta `datasets/fruits`. Hay 6 categorías de frutas: manzanas frescas, naranjas frescas, plátanos frescos, manzanas podridas, naranjas podridas y plátanos podridos. \n",
    "\n",
    "También necesitarás compilar el modelo con `categorical_crossentropy`, ya que tenemos más de dos categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/workspaces/DATASCIENCE/CEIABD_REPO/CEIABD_MODULOS_IA/SISTEMAS DE APRENDIZAJE AUTOMATICO/NOTEBOOKS DEL AULA/Redes Neuronales/img/fruits.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Modelo Base de Imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se recomienda empezar con un modelo preentrenado en ImageNet.    \n",
    "1. Cargar el modelo con los pesos correctos, establecer una forma de entrada y eliminar las últimas capas del modelo.    \n",
    "2. Recordar que las imágenes tienen tres dimensiones: una altura, una anchura y un número de canales.    \n",
    "3. Como estas imágenes son en color, habrá tres canales para el rojo, el verde y el azul.    \n",
    "4. Se ha preparado el formato de entrada. Esto no se puede cambiar o la evaluación fallará.    \n",
    "\n",
    "Si se necesita una referencia para configurar el modelo preentrenado, se puede consultar el notebook 06_RNA_Red_Convolucional_TransferLearning donde se implementa el aprendizaje por transferencia (Transfer Learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=,\n",
    "    input_shape=(),\n",
    "    include_top=) # no se incluye la capa densa final para poder añadir la nuestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congelamos el Modelo Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, sugerimos congelar el modelo base, como se hace en notebook citado anteriormente. Esto se hace para que todo el aprendizaje del conjunto de datos ImageNet no se destruya en el entrenamiento inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelamos las capas del modelo base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadir capas al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de añadir capas al modelo preentrenado. El notebook de Transfer Learning puede servir de guía. Se debe prestar atención a la última capa densa y asegurar que tiene el número correcto de neuronas para clasificar los diferentes tipos de fruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear capa de entrada con la forma correcta\n",
    "inputs = \n",
    "x = base_model()\n",
    "\n",
    "# Añadir capa de pooling o capa de aplanamiento(flatten)\n",
    "x = \n",
    "\n",
    "# Añadir la última capa densa\n",
    "outputs = \n",
    "\n",
    "# Combinar entradas y salidas para crear un modelo\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de compilar el modelo con opciones de pérdidas y métricas. Recuerda que estamos entrenando en una serie de categorías diferentes, en lugar de un problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = , metrics = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumentar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo deseas, intenta aumentar los datos para mejorar el conjunto de datos. Revisa los notebooks en los que hemos realizado este tipo de operaciones. También hay documentación para la clase [Keras ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class). Este paso es opcional, pero puede ser útil para llegar al 92% de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen_train = ImageDataGenerator()\n",
    "datagen_valid = ImageDataGenerator() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de cargar los conjuntos de datos de entrenamiento y validación. Elige las carpetas pertinentes, así como el `target_size` correcto de las imágenes (tiene que coincidir con la entrada de altura y anchura del modelo que has creado). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and iterate training dataset\n",
    "\n",
    "train_it = datagen_train.flow_from_directory(\n",
    "    \"/workspaces/DATASCIENCE/CEIABD_REPO/CEIABD_MODULOS_IA/SISTEMAS DE APRENDIZAJE AUTOMATICO/NOTEBOOKS DEL AULA/Redes Neuronales/datasets/fruits/dataset/dataset/train/\",,\n",
    ")\n",
    "# load and iterate validation dataset\n",
    "valid_it = datagen_valid.flow_from_directory(\n",
    "    \"/workspaces/DATASCIENCE/CEIABD_REPO/CEIABD_MODULOS_IA/SISTEMAS DE APRENDIZAJE AUTOMATICO/NOTEBOOKS DEL AULA/Redes Neuronales/datasets/fruits/dataset/valid/\",,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Es hora de entrenar el modelo! Pasa los iteradores `train` y `valid` a la función `fit` y establece el número de épocas deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Train samples: \",train_it.samples)\n",
    "print(\"Valid samples: \",valid_it.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descongelar el modelo y realizar Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ya ha alcanzado una precisión de validación del 92%, este paso es opcional. Si no es así, te proponemos que ajustes el modelo con una tasa de aprendizaje (`learning_rate`) muy baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelar el modelo base\n",
    "\n",
    "# Compilar el modelo con una tasa de aprendizaje (learning_rate) baja\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con suerte, ahora tienes un modelo que tiene una precisión de validación (accuracy) del 92% o superior. Si no es así, es posible que debas volver atrás y, o bien ejecutar más épocas de entrenamiento, o ajustar el aumento de datos.\n",
    "\n",
    "Una vez que dispongas de un buen resultado con la precisión de validación (accuracy), evalúa el modelo ejecutando la siguiente celda. La función de evaluación devolverá una tupla, donde el primer valor es la pérdida (loss), y el segundo valor es tu precisión(accuracy). Para tomarlo como bueno, el modelo deberá tener un valor de precisión del `92% o superior`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
